{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neural Networks\n",
    "===============\n",
    "\n",
    "Neural networks can be constructed using the ``torch.nn`` package.\n",
    "\n",
    "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
    "``autograd`` to define models and differentiate them.\n",
    "An ``nn.Module`` contains layers, and a method ``forward(input)``\\ that\n",
    "returns the ``output``.\n",
    "\n",
    "For example, look at this network that classifies digit images:\n",
    "\n",
    " <img src=\"mnist.png\">\n",
    "\n",
    "   convnet\n",
    "\n",
    "It is a simple feed-forward network. It takes the input, feeds it\n",
    "through several layers one after the other, and then finally gives the\n",
    "output.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or\n",
    "  weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:\n",
    "  ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "Define the network\n",
    "------------------\n",
    "\n",
    "Let’s define this network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        print(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        print(x)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define the ``forward`` function, and the ``backward``\n",
    "function (where gradients are computed) is automatically defined for you\n",
    "using ``autograd``.\n",
    "You can use any of the Tensor operations in the ``forward`` function.\n",
    "\n",
    "The learnable parameters of a model are returned by ``net.parameters()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.1747,  0.2379,  0.2957],\n",
      "          [-0.2444, -0.1385, -0.3193],\n",
      "          [ 0.1816, -0.1823, -0.1787]]],\n",
      "\n",
      "\n",
      "        [[[-0.1393,  0.0251, -0.0358],\n",
      "          [ 0.2521, -0.2158, -0.2462],\n",
      "          [-0.2887, -0.3185, -0.0333]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1014,  0.1034, -0.2346],\n",
      "          [-0.2334, -0.0576, -0.2960],\n",
      "          [ 0.2383, -0.2865, -0.0762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0397,  0.2311, -0.1128],\n",
      "          [ 0.1270,  0.0748, -0.2838],\n",
      "          [-0.1948, -0.0230,  0.2773]]],\n",
      "\n",
      "\n",
      "        [[[-0.1234,  0.0446, -0.2817],\n",
      "          [-0.2450, -0.0596,  0.2140],\n",
      "          [-0.1239, -0.0803,  0.0748]]],\n",
      "\n",
      "\n",
      "        [[[-0.1374,  0.3142,  0.2419],\n",
      "          [ 0.3094,  0.0460, -0.0511],\n",
      "          [ 0.2604,  0.0399,  0.1904]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0857, -0.0195, -0.2701,  0.1689,  0.0965,  0.1811],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 4.7490e-02,  5.1681e-02, -1.1837e-01],\n",
      "          [-5.0601e-02, -6.3670e-03,  1.0114e-01],\n",
      "          [-1.0266e-02, -1.2527e-01,  1.0082e-01]],\n",
      "\n",
      "         [[-3.1153e-02,  9.0842e-04, -4.2041e-02],\n",
      "          [ 7.3591e-02, -5.6103e-02, -5.2368e-02],\n",
      "          [-4.0974e-02,  4.7771e-02,  1.2696e-01]],\n",
      "\n",
      "         [[-4.3561e-02,  1.0070e-01,  1.3276e-01],\n",
      "          [-7.7887e-04,  4.9847e-02,  1.6670e-02],\n",
      "          [ 9.7737e-02,  3.3404e-02, -6.2042e-02]],\n",
      "\n",
      "         [[-1.1178e-01,  8.1385e-02,  5.7195e-02],\n",
      "          [ 1.7383e-02,  8.3424e-02,  1.1299e-01],\n",
      "          [ 8.9586e-02, -2.7144e-02,  1.7472e-02]],\n",
      "\n",
      "         [[-9.2331e-02,  2.6520e-02, -9.6725e-02],\n",
      "          [-8.3280e-02, -5.8319e-02, -9.8979e-02],\n",
      "          [ 2.1234e-03, -2.8614e-02, -4.0306e-02]],\n",
      "\n",
      "         [[-3.0027e-03, -1.3321e-01, -4.4458e-02],\n",
      "          [ 9.9648e-02, -3.9417e-02,  7.4993e-02],\n",
      "          [ 5.9442e-04, -6.1607e-03, -6.2520e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0639e-01, -1.2406e-01, -1.3207e-01],\n",
      "          [-8.2672e-02,  2.4335e-02, -1.7723e-02],\n",
      "          [-1.0676e-01, -7.6733e-02,  4.6073e-02]],\n",
      "\n",
      "         [[ 1.2243e-01,  8.1142e-02,  1.0193e-01],\n",
      "          [-1.1711e-01, -1.2321e-01,  1.2717e-01],\n",
      "          [-6.0723e-02,  1.9466e-02,  1.3198e-01]],\n",
      "\n",
      "         [[ 2.0386e-02,  9.0653e-02,  3.6666e-02],\n",
      "          [ 4.4653e-02, -1.1292e-01, -1.1958e-01],\n",
      "          [-3.1162e-02, -2.9226e-02, -3.0603e-02]],\n",
      "\n",
      "         [[ 2.8963e-02,  1.1616e-01,  5.2160e-02],\n",
      "          [ 9.5814e-02,  1.1013e-02,  3.2759e-02],\n",
      "          [ 2.4695e-02, -2.3534e-03, -9.0670e-02]],\n",
      "\n",
      "         [[ 7.0820e-02,  5.6440e-02, -4.5097e-02],\n",
      "          [ 3.0679e-02, -4.5429e-02, -3.5629e-02],\n",
      "          [-1.3475e-02, -6.0952e-03,  1.3067e-01]],\n",
      "\n",
      "         [[-4.4186e-02,  1.2181e-01, -2.7468e-02],\n",
      "          [ 8.6807e-02,  3.9888e-03,  5.5430e-02],\n",
      "          [-1.3509e-01,  2.6425e-02,  3.6421e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4504e-02,  1.5920e-03, -1.2650e-01],\n",
      "          [ 9.0486e-02, -1.0572e-01,  9.4226e-02],\n",
      "          [-7.0253e-03, -5.6135e-02, -9.1146e-03]],\n",
      "\n",
      "         [[-8.2605e-02,  8.1374e-02,  8.9427e-02],\n",
      "          [ 1.2394e-01,  2.4515e-02,  1.3340e-01],\n",
      "          [-4.4158e-02,  7.5645e-02,  9.8057e-02]],\n",
      "\n",
      "         [[ 2.6868e-02, -1.5070e-04,  1.0693e-01],\n",
      "          [-9.4196e-03,  1.7336e-02,  1.3471e-01],\n",
      "          [ 9.5675e-02, -2.8423e-02, -9.4242e-02]],\n",
      "\n",
      "         [[-1.0070e-01,  6.6627e-02, -5.6528e-02],\n",
      "          [-6.5821e-02,  1.2742e-01, -8.0307e-02],\n",
      "          [-9.4068e-02, -6.8442e-02,  3.5431e-02]],\n",
      "\n",
      "         [[-1.9627e-03, -7.5831e-02, -2.7349e-02],\n",
      "          [ 5.9730e-02,  8.2457e-02,  1.1597e-02],\n",
      "          [-9.7872e-02, -2.6287e-02, -3.9660e-03]],\n",
      "\n",
      "         [[ 6.7103e-02,  1.3219e-01, -7.7197e-02],\n",
      "          [ 1.0378e-02,  1.0901e-01, -3.0160e-02],\n",
      "          [-1.1485e-01,  4.9788e-02, -4.9754e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1931e-01, -7.9963e-02,  6.0163e-02],\n",
      "          [-4.9510e-02,  1.1687e-01,  1.1315e-01],\n",
      "          [-1.1124e-01,  1.0111e-01,  1.5467e-02]],\n",
      "\n",
      "         [[ 6.2552e-03,  8.1518e-02,  8.0752e-02],\n",
      "          [-7.9601e-02,  5.2583e-02,  3.7562e-02],\n",
      "          [-3.8246e-02,  4.6654e-02, -6.1947e-02]],\n",
      "\n",
      "         [[ 1.3486e-01,  5.1797e-02,  1.0102e-01],\n",
      "          [-5.3337e-04, -8.3940e-02, -7.9551e-02],\n",
      "          [ 6.3387e-02, -1.0639e-01,  3.4490e-02]],\n",
      "\n",
      "         [[ 1.0472e-02, -6.2694e-02,  7.5930e-02],\n",
      "          [-1.1869e-01, -3.7812e-02, -4.8274e-03],\n",
      "          [-3.4659e-02,  3.8854e-02, -6.3461e-02]],\n",
      "\n",
      "         [[ 1.2241e-01,  1.0891e-01,  4.0913e-02],\n",
      "          [-5.3155e-02, -7.1461e-02,  4.3347e-02],\n",
      "          [ 5.6524e-02, -2.2869e-02,  1.1530e-02]],\n",
      "\n",
      "         [[-7.2627e-02, -7.5361e-02,  4.5990e-02],\n",
      "          [ 2.6161e-02, -1.0051e-02,  7.6867e-02],\n",
      "          [ 3.3251e-02,  1.6019e-02,  3.7994e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0980e-02, -1.3397e-01,  5.3235e-02],\n",
      "          [ 5.8235e-02,  6.6707e-02, -1.0154e-01],\n",
      "          [-5.4864e-02,  4.2167e-02,  9.4552e-02]],\n",
      "\n",
      "         [[ 7.3970e-02,  1.3536e-01, -1.3422e-01],\n",
      "          [-1.0644e-01,  3.5614e-02, -1.0605e-01],\n",
      "          [-1.3345e-02,  1.0363e-01,  9.1526e-02]],\n",
      "\n",
      "         [[ 9.4223e-02,  4.3975e-02,  4.1113e-02],\n",
      "          [ 3.9366e-02, -5.5745e-02, -1.3783e-03],\n",
      "          [-1.3247e-01, -7.0504e-02,  1.2256e-01]],\n",
      "\n",
      "         [[-1.2683e-01, -2.7692e-02, -1.0987e-01],\n",
      "          [ 4.8429e-02,  6.5587e-02, -5.4133e-02],\n",
      "          [ 3.3949e-03,  5.4343e-02,  1.3116e-01]],\n",
      "\n",
      "         [[-5.5852e-02, -1.1757e-01, -1.0201e-01],\n",
      "          [ 9.1054e-02, -1.0231e-01,  7.1154e-02],\n",
      "          [-7.4000e-02, -6.1710e-03,  9.2820e-02]],\n",
      "\n",
      "         [[ 4.8340e-02,  5.2302e-02,  1.2341e-01],\n",
      "          [-4.8960e-02, -1.4550e-02,  9.3520e-02],\n",
      "          [-1.0303e-01, -5.1172e-02, -7.5071e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0640e-02, -1.1591e-01, -5.8952e-02],\n",
      "          [ 8.5658e-02, -7.4686e-02,  9.6965e-02],\n",
      "          [ 2.5538e-02,  1.1689e-01,  4.4308e-02]],\n",
      "\n",
      "         [[ 9.8657e-02, -2.0734e-02,  5.1239e-02],\n",
      "          [ 9.2494e-02,  1.7053e-02,  8.3329e-02],\n",
      "          [ 9.2485e-02,  3.8596e-02,  2.1934e-02]],\n",
      "\n",
      "         [[ 7.1261e-02,  3.6814e-02, -9.3394e-02],\n",
      "          [ 8.0632e-03,  4.7051e-02,  3.6250e-03],\n",
      "          [-1.3435e-01,  1.1159e-01,  3.6262e-02]],\n",
      "\n",
      "         [[ 7.6619e-02,  2.2496e-02,  3.4515e-02],\n",
      "          [-6.9144e-03, -1.0239e-01,  1.3471e-01],\n",
      "          [ 7.1606e-02,  9.0123e-02,  1.0564e-02]],\n",
      "\n",
      "         [[-1.1432e-01,  1.3371e-01,  1.9397e-02],\n",
      "          [-1.2895e-01,  6.6382e-02, -1.1438e-01],\n",
      "          [ 2.8646e-02,  6.4043e-02, -7.9403e-03]],\n",
      "\n",
      "         [[-6.1878e-02, -3.1674e-02, -8.9975e-02],\n",
      "          [ 4.7009e-02, -9.3372e-02, -9.1380e-02],\n",
      "          [ 3.0630e-02, -1.2011e-02, -5.5958e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4815e-02, -4.5092e-02,  1.8478e-02],\n",
      "          [ 1.0187e-01,  3.3106e-02,  6.8763e-02],\n",
      "          [-2.6375e-02,  1.2041e-01, -1.1416e-02]],\n",
      "\n",
      "         [[-1.1526e-01,  2.2869e-02,  4.5117e-02],\n",
      "          [ 8.1297e-02, -4.2324e-02,  1.6813e-02],\n",
      "          [-1.1240e-01, -6.5449e-02,  3.1811e-02]],\n",
      "\n",
      "         [[ 3.8149e-02,  1.6560e-02, -6.9229e-02],\n",
      "          [ 1.0636e-01, -2.1000e-02, -5.1509e-02],\n",
      "          [-1.9065e-02, -1.1056e-01,  1.1001e-01]],\n",
      "\n",
      "         [[ 7.0848e-03,  3.4845e-02, -1.0680e-01],\n",
      "          [-9.8501e-02,  4.4593e-02,  7.7884e-02],\n",
      "          [-1.2903e-01, -1.2837e-02,  9.1343e-02]],\n",
      "\n",
      "         [[ 3.5675e-02, -9.1102e-02,  3.6581e-02],\n",
      "          [ 5.9463e-03,  1.3250e-02, -1.1626e-02],\n",
      "          [ 1.1677e-01,  5.8501e-02, -7.2324e-04]],\n",
      "\n",
      "         [[-2.2277e-02,  1.1923e-01, -1.2185e-01],\n",
      "          [-1.1216e-01, -9.2523e-02, -8.7951e-03],\n",
      "          [ 3.2939e-02, -5.3263e-02,  3.2133e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0151e-01, -1.0186e-01, -1.7125e-02],\n",
      "          [ 8.2807e-02,  3.7375e-02, -1.2300e-03],\n",
      "          [-4.8789e-02,  8.5195e-02, -7.5017e-02]],\n",
      "\n",
      "         [[-3.4066e-02,  9.4725e-02,  1.2189e-01],\n",
      "          [ 5.1013e-02, -7.7261e-02,  9.5954e-02],\n",
      "          [-3.4469e-02, -1.1896e-02, -1.0422e-01]],\n",
      "\n",
      "         [[ 7.7315e-02, -4.0239e-03,  2.5204e-02],\n",
      "          [-9.1588e-04, -8.7252e-02,  9.0800e-03],\n",
      "          [-6.8334e-02,  9.6415e-03,  4.6414e-02]],\n",
      "\n",
      "         [[-1.0629e-01,  2.8468e-02, -8.5031e-02],\n",
      "          [ 3.0472e-02, -7.6210e-02, -1.1135e-01],\n",
      "          [ 4.1643e-02,  4.7171e-02,  4.4154e-02]],\n",
      "\n",
      "         [[ 3.5339e-02, -1.1870e-02,  7.9580e-02],\n",
      "          [-7.6993e-02,  7.7540e-02,  1.2571e-01],\n",
      "          [-1.2866e-01,  7.3499e-02,  8.1480e-02]],\n",
      "\n",
      "         [[ 1.0494e-01,  6.8159e-02, -5.1331e-02],\n",
      "          [-1.2525e-01,  8.7066e-02, -4.7316e-02],\n",
      "          [-9.5168e-03,  1.0099e-01, -1.1638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0597e-01, -6.0572e-02,  1.2947e-01],\n",
      "          [-1.1396e-01, -7.1468e-02,  1.0737e-01],\n",
      "          [-5.8777e-02,  3.9016e-02, -8.2992e-02]],\n",
      "\n",
      "         [[ 1.1647e-02,  5.5836e-02, -1.0597e-01],\n",
      "          [-1.0474e-01,  3.7828e-02, -1.6795e-02],\n",
      "          [ 6.1671e-02, -6.8547e-02,  1.1210e-01]],\n",
      "\n",
      "         [[ 1.4390e-02,  6.4060e-02, -1.3526e-01],\n",
      "          [-2.4800e-02,  3.7031e-02, -7.8093e-02],\n",
      "          [-6.8814e-02, -9.5217e-03, -6.9768e-02]],\n",
      "\n",
      "         [[ 5.6951e-02, -3.0458e-02,  5.0811e-02],\n",
      "          [ 1.3196e-04,  1.3317e-01,  7.8530e-03],\n",
      "          [-1.3263e-01, -1.3216e-01,  7.3673e-02]],\n",
      "\n",
      "         [[ 1.0757e-01, -9.2808e-02, -1.0719e-01],\n",
      "          [ 2.0705e-02, -1.5675e-02, -6.8017e-02],\n",
      "          [-9.9595e-02,  5.5990e-02, -4.3320e-02]],\n",
      "\n",
      "         [[ 2.1883e-02,  8.3705e-02, -1.0901e-01],\n",
      "          [-8.3383e-02,  4.1115e-02, -1.2103e-01],\n",
      "          [-2.4328e-02,  1.2034e-01,  1.0444e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5328e-02, -1.2382e-02, -4.3049e-02],\n",
      "          [-8.6306e-03,  1.1081e-01, -1.1789e-01],\n",
      "          [ 2.2260e-02,  1.1932e-01, -1.3383e-01]],\n",
      "\n",
      "         [[-1.0338e-01,  4.7472e-02, -4.8253e-02],\n",
      "          [-7.4272e-03,  1.2084e-01, -7.0756e-02],\n",
      "          [ 6.9384e-02, -5.2732e-02,  1.3175e-01]],\n",
      "\n",
      "         [[-7.6241e-02, -1.2347e-01, -1.1974e-01],\n",
      "          [-9.5546e-02,  6.8757e-02, -6.2843e-02],\n",
      "          [ 9.7439e-02, -7.0888e-02, -1.0675e-01]],\n",
      "\n",
      "         [[-6.9651e-02, -1.2324e-01,  7.2611e-02],\n",
      "          [ 4.3778e-02,  1.1414e-02, -1.2480e-01],\n",
      "          [-5.9621e-02,  1.1897e-01,  6.0638e-02]],\n",
      "\n",
      "         [[ 3.8109e-02,  9.2914e-03,  2.2130e-02],\n",
      "          [-4.7528e-02,  5.7413e-02,  8.1877e-03],\n",
      "          [-6.7730e-02,  1.1436e-01,  7.6970e-03]],\n",
      "\n",
      "         [[-6.4862e-02,  9.2480e-02, -8.4643e-02],\n",
      "          [-1.3031e-01, -7.0732e-02, -7.0215e-02],\n",
      "          [ 5.5618e-02,  7.5014e-02, -1.6344e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0869e-02,  3.1408e-02, -7.6942e-02],\n",
      "          [-3.4505e-02,  6.3803e-02,  9.9019e-02],\n",
      "          [ 1.3083e-01, -7.4221e-02, -6.3338e-02]],\n",
      "\n",
      "         [[-9.5559e-02,  5.8322e-02,  4.8152e-02],\n",
      "          [ 1.3345e-01, -1.2954e-01,  9.4642e-02],\n",
      "          [ 1.1758e-01, -6.2515e-02,  8.8464e-02]],\n",
      "\n",
      "         [[ 6.7067e-02,  1.0967e-01, -5.2584e-02],\n",
      "          [ 3.7223e-02,  7.8299e-02,  5.3225e-02],\n",
      "          [ 2.7172e-02, -1.0209e-01, -1.2078e-01]],\n",
      "\n",
      "         [[-1.2569e-01,  1.1225e-01,  8.9472e-02],\n",
      "          [-8.0682e-02, -7.9118e-02, -4.2719e-02],\n",
      "          [-7.6455e-02,  7.6980e-02, -6.8760e-02]],\n",
      "\n",
      "         [[-6.6709e-02,  4.8928e-04, -4.7970e-02],\n",
      "          [ 1.7209e-02,  1.2852e-01, -9.6459e-02],\n",
      "          [-8.9435e-02, -1.1147e-01,  1.2901e-01]],\n",
      "\n",
      "         [[-8.8413e-02, -2.2330e-02, -1.3546e-01],\n",
      "          [-6.1949e-02,  1.0266e-01, -1.0023e-01],\n",
      "          [ 1.1003e-01, -6.1657e-02,  1.5349e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1892e-02,  4.3401e-02, -5.0336e-02],\n",
      "          [-1.0486e-01, -8.9943e-02,  9.2976e-02],\n",
      "          [ 8.3831e-02,  3.4007e-02,  1.0021e-01]],\n",
      "\n",
      "         [[ 5.0981e-02, -1.3377e-01,  1.0351e-01],\n",
      "          [-2.7279e-02, -5.6988e-03,  1.0488e-01],\n",
      "          [ 7.0616e-02, -9.0734e-02,  1.0109e-01]],\n",
      "\n",
      "         [[-5.0415e-02,  3.7478e-02, -1.3542e-01],\n",
      "          [ 7.1816e-02, -1.5809e-02,  1.2820e-01],\n",
      "          [-1.1076e-02,  2.5350e-02, -1.0593e-01]],\n",
      "\n",
      "         [[-7.8067e-02, -1.3531e-01,  5.5357e-02],\n",
      "          [-7.1681e-02,  1.0166e-01,  1.3404e-01],\n",
      "          [-1.3398e-01,  7.6143e-02,  1.2726e-01]],\n",
      "\n",
      "         [[-9.5058e-02,  1.0166e-01, -9.1908e-02],\n",
      "          [ 4.2395e-02, -8.3458e-02, -6.5920e-02],\n",
      "          [ 6.4264e-02,  2.7327e-02,  9.9550e-03]],\n",
      "\n",
      "         [[ 1.0725e-01,  2.4873e-02, -1.0339e-01],\n",
      "          [ 2.0402e-02,  1.2144e-01, -5.9473e-02],\n",
      "          [-3.4739e-02, -1.0735e-01, -1.1211e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3087e-02, -7.2604e-04, -5.8399e-02],\n",
      "          [ 4.7017e-02,  1.1775e-01,  3.8429e-02],\n",
      "          [-8.6016e-02, -1.1898e-01, -2.3640e-02]],\n",
      "\n",
      "         [[-4.4053e-02,  3.9358e-02, -7.3343e-02],\n",
      "          [-1.0877e-01, -1.0345e-01,  1.2779e-02],\n",
      "          [ 6.1724e-02,  1.1295e-01,  9.4038e-02]],\n",
      "\n",
      "         [[-9.2589e-02, -1.8900e-02, -8.4359e-02],\n",
      "          [-1.0378e-01, -1.1887e-01, -7.0262e-02],\n",
      "          [ 1.5124e-03, -1.2500e-01,  2.7769e-02]],\n",
      "\n",
      "         [[-4.9548e-02,  1.2867e-01, -1.1054e-01],\n",
      "          [ 5.2569e-02,  4.4578e-02, -2.6018e-02],\n",
      "          [ 8.5932e-02,  6.0304e-02, -4.3781e-02]],\n",
      "\n",
      "         [[ 1.2960e-01, -6.5656e-02,  5.6726e-02],\n",
      "          [ 1.2560e-02, -6.0728e-02,  5.0776e-02],\n",
      "          [ 2.7462e-02,  4.0404e-02, -9.4866e-02]],\n",
      "\n",
      "         [[-1.5444e-02,  1.2024e-01, -8.1139e-02],\n",
      "          [-9.9194e-03,  2.3791e-02, -2.7865e-02],\n",
      "          [-9.4977e-02, -6.9063e-02, -3.2093e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2388e-02, -1.0255e-01,  7.8564e-02],\n",
      "          [-1.0117e-01,  1.0877e-01, -9.9480e-02],\n",
      "          [-4.2198e-02,  5.0360e-02, -3.1147e-02]],\n",
      "\n",
      "         [[-1.1404e-01, -8.5361e-02,  6.1192e-03],\n",
      "          [-3.2719e-02, -1.2313e-01, -1.3370e-01],\n",
      "          [-4.7582e-02, -2.9492e-02, -7.8887e-02]],\n",
      "\n",
      "         [[-8.3341e-02, -2.4397e-02, -1.3066e-01],\n",
      "          [ 1.0285e-01,  1.0363e-01,  8.7810e-02],\n",
      "          [-7.4435e-02,  3.3529e-02,  7.8533e-02]],\n",
      "\n",
      "         [[-1.3201e-01,  9.7787e-02, -4.4974e-02],\n",
      "          [-2.0102e-02,  1.2173e-01,  1.1592e-01],\n",
      "          [-1.1661e-01, -6.9795e-02,  9.8940e-02]],\n",
      "\n",
      "         [[-1.0241e-01, -1.1823e-01,  1.4293e-02],\n",
      "          [-2.9746e-02, -7.3313e-02,  1.3583e-01],\n",
      "          [-1.1404e-01, -1.5452e-02,  6.5271e-02]],\n",
      "\n",
      "         [[-5.4165e-03,  7.9135e-02,  5.1680e-02],\n",
      "          [-9.0436e-02,  5.4849e-02,  5.4594e-02],\n",
      "          [ 9.2376e-02, -7.1163e-02,  1.0832e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.0882e-02,  1.0849e-01,  1.2623e-01],\n",
      "          [ 6.4062e-03, -6.0077e-02, -1.1870e-01],\n",
      "          [ 3.8641e-02,  4.1813e-02, -1.0293e-01]],\n",
      "\n",
      "         [[ 8.5241e-02, -7.6887e-02, -1.1267e-01],\n",
      "          [-1.3448e-01, -2.7396e-02,  6.6094e-02],\n",
      "          [-9.0788e-02, -1.3192e-01,  1.2745e-01]],\n",
      "\n",
      "         [[ 6.2340e-02, -5.0112e-02,  2.8750e-02],\n",
      "          [-3.0554e-02, -8.1636e-02,  7.1026e-02],\n",
      "          [ 1.5506e-02,  2.8928e-02, -7.0253e-02]],\n",
      "\n",
      "         [[-4.2191e-02, -9.8059e-02, -1.7050e-02],\n",
      "          [-4.3369e-02, -1.7936e-02, -6.3528e-02],\n",
      "          [-9.5048e-02, -8.4988e-02, -4.8621e-04]],\n",
      "\n",
      "         [[-8.5308e-02,  3.0234e-05, -1.1269e-01],\n",
      "          [ 1.2867e-01,  9.5451e-02,  5.8456e-03],\n",
      "          [-5.3413e-03, -7.9840e-02,  1.1580e-01]],\n",
      "\n",
      "         [[ 2.5297e-02, -2.2254e-02, -6.2399e-02],\n",
      "          [-5.2754e-02, -1.2752e-01, -3.3452e-03],\n",
      "          [-1.2883e-01,  7.0003e-02, -5.5683e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0543e-01,  5.2828e-03,  1.3158e-01],\n",
      "          [ 6.0617e-02,  8.5503e-02, -1.1726e-01],\n",
      "          [ 9.2585e-02, -5.7927e-02,  3.8837e-02]],\n",
      "\n",
      "         [[-1.2073e-01,  9.1786e-02,  1.2519e-01],\n",
      "          [-2.1986e-02,  4.5038e-02,  1.0695e-01],\n",
      "          [-8.2775e-02, -9.3043e-02, -2.8746e-02]],\n",
      "\n",
      "         [[-5.3937e-02,  8.6271e-02, -5.1410e-02],\n",
      "          [-1.5719e-02,  1.0688e-01,  9.4062e-02],\n",
      "          [ 1.3429e-01,  6.8415e-02, -8.6573e-02]],\n",
      "\n",
      "         [[ 6.4421e-02, -1.2021e-02, -9.0617e-02],\n",
      "          [ 3.9948e-02, -6.4050e-02, -1.1166e-01],\n",
      "          [ 9.4001e-02,  1.2493e-01,  1.2472e-01]],\n",
      "\n",
      "         [[-2.6629e-02, -8.4697e-02, -1.1383e-01],\n",
      "          [ 1.8828e-02,  6.1835e-02,  7.7740e-02],\n",
      "          [ 5.7779e-02,  1.0922e-01,  2.1465e-02]],\n",
      "\n",
      "         [[-2.5398e-02,  6.9017e-02, -9.7450e-03],\n",
      "          [ 6.7342e-02, -1.1607e-01, -3.9805e-02],\n",
      "          [ 3.3814e-02, -6.6765e-02, -6.4448e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0777,  0.1049, -0.0354,  0.0121, -0.0290,  0.0772,  0.0119,  0.0792,\n",
      "        -0.1269,  0.0207, -0.1062,  0.0272, -0.0009,  0.0207, -0.1101, -0.0604],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0078,  0.0045,  0.0377,  ..., -0.0004, -0.0221,  0.0072],\n",
      "        [-0.0097, -0.0063,  0.0165,  ...,  0.0056,  0.0067,  0.0079],\n",
      "        [ 0.0037,  0.0345,  0.0146,  ...,  0.0323, -0.0229,  0.0394],\n",
      "        ...,\n",
      "        [-0.0015,  0.0038, -0.0084,  ..., -0.0161,  0.0227, -0.0026],\n",
      "        [-0.0084, -0.0064,  0.0129,  ...,  0.0353,  0.0156,  0.0398],\n",
      "        [-0.0111, -0.0197,  0.0186,  ...,  0.0130,  0.0392,  0.0357]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0317,  0.0179, -0.0126,  0.0015, -0.0003, -0.0102, -0.0301, -0.0241,\n",
      "        -0.0175,  0.0304,  0.0275, -0.0030,  0.0205, -0.0252, -0.0150,  0.0212,\n",
      "         0.0374, -0.0223, -0.0347,  0.0352, -0.0096,  0.0136, -0.0365, -0.0099,\n",
      "        -0.0079,  0.0317, -0.0377, -0.0170,  0.0303,  0.0159, -0.0010, -0.0358,\n",
      "         0.0098, -0.0235,  0.0215,  0.0321, -0.0138,  0.0308,  0.0089,  0.0207,\n",
      "        -0.0062, -0.0056, -0.0279,  0.0014, -0.0015, -0.0128, -0.0204,  0.0370,\n",
      "        -0.0068,  0.0112,  0.0383, -0.0202,  0.0142, -0.0352, -0.0120,  0.0412,\n",
      "         0.0211, -0.0349, -0.0033, -0.0057,  0.0336, -0.0394,  0.0296,  0.0179,\n",
      "         0.0152,  0.0120,  0.0070, -0.0102, -0.0402,  0.0135,  0.0068,  0.0234,\n",
      "         0.0126,  0.0159,  0.0194, -0.0307,  0.0337,  0.0092, -0.0299,  0.0231,\n",
      "         0.0398,  0.0299, -0.0231, -0.0105, -0.0006, -0.0373,  0.0334,  0.0240,\n",
      "        -0.0106,  0.0029,  0.0310, -0.0091, -0.0392,  0.0407,  0.0149,  0.0066,\n",
      "         0.0366,  0.0092, -0.0264,  0.0271,  0.0414,  0.0379, -0.0392,  0.0281,\n",
      "         0.0102, -0.0015,  0.0052,  0.0246, -0.0122, -0.0250,  0.0346, -0.0044,\n",
      "        -0.0342,  0.0090, -0.0068,  0.0007, -0.0017,  0.0239, -0.0307, -0.0089],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0745, -0.0201, -0.0528,  ..., -0.0422,  0.0179, -0.0795],\n",
      "        [-0.0205,  0.0500,  0.0877,  ..., -0.0171,  0.0724, -0.0087],\n",
      "        [ 0.0736, -0.0065, -0.0698,  ..., -0.0894, -0.0881, -0.0781],\n",
      "        ...,\n",
      "        [-0.0472, -0.0441, -0.0127,  ...,  0.0164,  0.0382,  0.0622],\n",
      "        [ 0.0436, -0.0193, -0.0497,  ...,  0.0112,  0.0469,  0.0402],\n",
      "        [ 0.0904, -0.0559,  0.0025,  ..., -0.0107,  0.0810, -0.0657]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0845, -0.0574,  0.0338, -0.0752, -0.0262,  0.0699, -0.0138, -0.0846,\n",
      "         0.0040, -0.0366,  0.0672, -0.0507,  0.0714,  0.0056, -0.0716, -0.0388,\n",
      "         0.0321,  0.0225, -0.0104,  0.0498, -0.0789,  0.0026, -0.0194, -0.0607,\n",
      "         0.0209,  0.0781, -0.0008,  0.0845,  0.0138,  0.0664, -0.0736, -0.0187,\n",
      "        -0.0294, -0.0502, -0.0487,  0.0148,  0.0172, -0.0462, -0.0310, -0.0350,\n",
      "        -0.0586, -0.0503,  0.0097,  0.0205,  0.0286, -0.0607, -0.0026, -0.0465,\n",
      "         0.0603, -0.0525, -0.0263,  0.0601,  0.0357,  0.0287,  0.0320,  0.0005,\n",
      "         0.0823, -0.0056,  0.0778, -0.0294,  0.0062,  0.0873, -0.0881, -0.0468,\n",
      "         0.0880,  0.0409,  0.0833, -0.0532, -0.0235, -0.0157,  0.0578,  0.0568,\n",
      "         0.0147,  0.0321, -0.0670,  0.0896, -0.0845,  0.0758,  0.0656,  0.0502,\n",
      "        -0.0177, -0.0105,  0.0553,  0.0450], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0545,  0.0768,  0.0953, -0.0355, -0.0774,  0.0358,  0.0055, -0.0047,\n",
      "          0.0332,  0.0626,  0.0725,  0.0230, -0.0409, -0.0988, -0.0663,  0.0308,\n",
      "         -0.0399, -0.0951, -0.0469, -0.1011, -0.0215, -0.0002,  0.0621,  0.0611,\n",
      "          0.0678,  0.0662,  0.0099,  0.0584, -0.0104, -0.0913, -0.0173, -0.1079,\n",
      "         -0.0314, -0.1013,  0.0033,  0.0558, -0.0955, -0.1016, -0.0583, -0.0266,\n",
      "         -0.0369,  0.0411, -0.0088, -0.0888, -0.0539,  0.1079, -0.0282,  0.0791,\n",
      "         -0.0801, -0.0064,  0.0734, -0.0782,  0.0862,  0.0526,  0.1002,  0.0128,\n",
      "          0.0109, -0.0679, -0.0583, -0.0244, -0.0517,  0.0289,  0.0115, -0.0493,\n",
      "          0.1052,  0.0546, -0.0002, -0.0467, -0.0155, -0.0788, -0.0455,  0.0574,\n",
      "         -0.0597,  0.0601,  0.0217, -0.1073,  0.0243, -0.0940, -0.0843, -0.0890,\n",
      "         -0.0594,  0.0849, -0.0936, -0.1039],\n",
      "        [ 0.0595,  0.0538,  0.0633, -0.0201,  0.0476,  0.1042, -0.0320,  0.0721,\n",
      "         -0.0075, -0.0902,  0.0305,  0.0179,  0.0811, -0.0325,  0.0767,  0.0818,\n",
      "         -0.0636, -0.0979,  0.0797,  0.0047,  0.0659, -0.0925,  0.0385, -0.0009,\n",
      "          0.0757, -0.0472, -0.1040,  0.0700, -0.0608, -0.0068,  0.0233,  0.0796,\n",
      "         -0.0740,  0.0903,  0.0521, -0.0024,  0.0804, -0.0074, -0.0703, -0.0642,\n",
      "         -0.0449,  0.0868,  0.0096, -0.0648, -0.0721,  0.0018,  0.0294, -0.0990,\n",
      "          0.1074,  0.0696,  0.1005, -0.0604,  0.0106, -0.0111, -0.0697, -0.0402,\n",
      "          0.0396, -0.0485, -0.0414,  0.0308, -0.0160,  0.0509,  0.0279, -0.0554,\n",
      "         -0.0917,  0.0508, -0.0891, -0.0669, -0.1042, -0.0240, -0.1075,  0.0240,\n",
      "         -0.1063,  0.0012,  0.0229, -0.0456,  0.0490, -0.0188,  0.0723,  0.0978,\n",
      "         -0.0238, -0.0017,  0.0737,  0.0398],\n",
      "        [-0.0778,  0.0257,  0.0787, -0.0667,  0.0520,  0.0755, -0.0135, -0.0058,\n",
      "         -0.0201,  0.1063, -0.0785, -0.1028,  0.0559,  0.0676,  0.0322, -0.0172,\n",
      "         -0.0810,  0.0846,  0.0239,  0.0058,  0.0729,  0.0628,  0.0715,  0.0466,\n",
      "          0.0076, -0.0382,  0.0464, -0.0704,  0.0517, -0.0624,  0.0313,  0.0407,\n",
      "          0.0992, -0.0378,  0.0430, -0.0791, -0.0196, -0.0524, -0.0074, -0.0830,\n",
      "          0.0169,  0.0789,  0.0360, -0.0416,  0.0550,  0.0742,  0.0534, -0.0690,\n",
      "         -0.0765, -0.0532,  0.0120,  0.0523, -0.0897,  0.0510,  0.0110,  0.0876,\n",
      "         -0.0762, -0.0875, -0.0511,  0.0379,  0.0368, -0.0518, -0.0956,  0.0270,\n",
      "          0.1054,  0.0930, -0.0316, -0.0407, -0.0418,  0.0510, -0.0925, -0.0311,\n",
      "         -0.0721,  0.0362, -0.0746, -0.0372, -0.1057,  0.0256,  0.0124, -0.0415,\n",
      "         -0.0744,  0.0506, -0.0909,  0.0813],\n",
      "        [-0.0268, -0.0756, -0.0899,  0.0905,  0.0273, -0.0803, -0.0475,  0.0299,\n",
      "          0.0878,  0.0225,  0.0109, -0.1060,  0.0173, -0.0094,  0.0739,  0.0323,\n",
      "          0.0595, -0.0003,  0.0792, -0.0445,  0.0369,  0.0652,  0.0035, -0.0347,\n",
      "          0.0132, -0.0164,  0.0460,  0.0956,  0.0497, -0.0475,  0.0632,  0.0047,\n",
      "         -0.0517, -0.0266, -0.0422,  0.0648,  0.0624,  0.0678,  0.0537,  0.0359,\n",
      "          0.0278, -0.0985, -0.0895,  0.0054, -0.0719,  0.0913, -0.0133, -0.0703,\n",
      "         -0.0237, -0.0042,  0.0246,  0.0618, -0.0491, -0.0928,  0.0945, -0.0320,\n",
      "         -0.0448,  0.0893,  0.1041, -0.0566,  0.0894, -0.0702, -0.0877, -0.0813,\n",
      "          0.0379,  0.0837, -0.0151,  0.0231, -0.0843, -0.0353, -0.0972,  0.0448,\n",
      "         -0.0704, -0.0171,  0.0010, -0.0897, -0.1088,  0.0909,  0.0628,  0.1029,\n",
      "          0.0086, -0.0562, -0.0457,  0.0483],\n",
      "        [ 0.0418, -0.0680,  0.1021,  0.0064, -0.0364,  0.0590,  0.0545,  0.0878,\n",
      "          0.1019, -0.0907,  0.1052, -0.0312,  0.0423, -0.0037,  0.0944, -0.0025,\n",
      "         -0.0653,  0.0751,  0.0873,  0.0772,  0.1014, -0.0834, -0.0868,  0.0236,\n",
      "         -0.0579, -0.0451,  0.0655,  0.0746,  0.0817,  0.0107,  0.0823, -0.0445,\n",
      "          0.0072,  0.0901, -0.0273,  0.0134, -0.0473,  0.0515,  0.0732,  0.1052,\n",
      "         -0.0669,  0.0034, -0.0247, -0.0588,  0.0675,  0.1050, -0.1005,  0.0632,\n",
      "         -0.0785,  0.0035, -0.0964, -0.0225, -0.0931, -0.0338, -0.0508, -0.1012,\n",
      "         -0.0198,  0.0760,  0.0422, -0.0964,  0.0477, -0.0387, -0.0522,  0.0607,\n",
      "         -0.0915, -0.0878,  0.1025, -0.0838, -0.0258, -0.0966,  0.0274,  0.0902,\n",
      "         -0.0054, -0.0958, -0.0091,  0.0146, -0.0431,  0.0226,  0.0735,  0.0690,\n",
      "          0.0116, -0.0196,  0.0227, -0.0757],\n",
      "        [ 0.0190, -0.0386,  0.0867,  0.1054,  0.0167,  0.0810,  0.0884,  0.0957,\n",
      "         -0.0861,  0.0502, -0.0339, -0.0856, -0.0663, -0.0731, -0.0489,  0.0074,\n",
      "         -0.0885,  0.0560, -0.0359, -0.0176,  0.0158, -0.0555,  0.0164, -0.0170,\n",
      "          0.0498,  0.0441,  0.0242, -0.1023,  0.0074, -0.0800, -0.0454, -0.0680,\n",
      "         -0.1034,  0.0715,  0.0297, -0.0386, -0.0453, -0.0744,  0.0665, -0.0430,\n",
      "         -0.0967, -0.0907,  0.0202,  0.0479, -0.1064,  0.0082,  0.0342, -0.0695,\n",
      "          0.0618,  0.0767,  0.0222, -0.0799, -0.0852,  0.0441,  0.0243, -0.0121,\n",
      "          0.0893, -0.0804, -0.0166,  0.0814,  0.0740, -0.0658, -0.0041,  0.0965,\n",
      "         -0.0054,  0.0642, -0.1023, -0.0637, -0.0811,  0.0289, -0.0784, -0.0542,\n",
      "          0.0601,  0.0694, -0.0829, -0.0306,  0.0083,  0.0067,  0.0122, -0.0545,\n",
      "          0.0232, -0.0866,  0.0595,  0.0597],\n",
      "        [-0.0144,  0.0832,  0.0715, -0.0823,  0.0177, -0.0545,  0.0103,  0.0884,\n",
      "          0.0543,  0.0430,  0.0910,  0.0697,  0.0518, -0.0435, -0.0384,  0.0109,\n",
      "         -0.0957,  0.0479,  0.0441, -0.0192,  0.0339,  0.0750,  0.0045,  0.0567,\n",
      "          0.0499, -0.0126, -0.1087,  0.0183,  0.0387, -0.0707, -0.0457,  0.0865,\n",
      "         -0.0260,  0.0718,  0.0261,  0.0912, -0.0839, -0.0645,  0.0623,  0.0905,\n",
      "          0.0513,  0.0524, -0.0159,  0.0243, -0.0516,  0.1023, -0.0664, -0.0821,\n",
      "         -0.0175, -0.0233,  0.0287,  0.0661,  0.0527, -0.0853, -0.0418, -0.0638,\n",
      "          0.0824, -0.0425,  0.0802,  0.0756,  0.0605, -0.1017, -0.0493,  0.0208,\n",
      "          0.0868,  0.1037,  0.0933, -0.0520,  0.0175,  0.0057, -0.0520, -0.0950,\n",
      "          0.0212,  0.0330,  0.0103,  0.0852,  0.0473, -0.0102,  0.0083,  0.0963,\n",
      "         -0.0938,  0.1010,  0.0002,  0.0112],\n",
      "        [-0.0361, -0.0624,  0.0660, -0.0227, -0.0571, -0.0723,  0.0902, -0.0847,\n",
      "          0.0050, -0.0313,  0.0965, -0.0801, -0.0384, -0.0412,  0.0446, -0.0338,\n",
      "          0.0989, -0.0118,  0.0652, -0.0158,  0.0996, -0.0400,  0.0735,  0.0785,\n",
      "          0.0230,  0.0288,  0.0823, -0.0110,  0.0363,  0.0726,  0.0712, -0.0297,\n",
      "          0.0082, -0.0933,  0.0334,  0.0692, -0.0334, -0.0689, -0.1080,  0.0171,\n",
      "          0.0847,  0.0300,  0.0118,  0.0578, -0.0540, -0.0982,  0.0417, -0.0078,\n",
      "         -0.0260,  0.0093, -0.0571,  0.0056, -0.0827, -0.0501,  0.1063, -0.0659,\n",
      "         -0.1022,  0.0991, -0.0018,  0.0772, -0.0300, -0.0452,  0.0088,  0.0076,\n",
      "          0.0552,  0.0907,  0.0411, -0.0863,  0.0577,  0.0542,  0.0106,  0.0748,\n",
      "          0.0306, -0.0667, -0.0782,  0.0693,  0.0126, -0.0629, -0.0958,  0.0728,\n",
      "          0.0156, -0.0399,  0.0452,  0.0303],\n",
      "        [ 0.0104, -0.0703,  0.0615, -0.0464,  0.1072, -0.0715,  0.0814,  0.0152,\n",
      "          0.0773, -0.0018, -0.0112, -0.0257, -0.0015,  0.0656, -0.0409,  0.0461,\n",
      "          0.0608, -0.0782, -0.0166, -0.0073, -0.0025, -0.0268,  0.0695,  0.1021,\n",
      "         -0.0260,  0.0859,  0.0089, -0.0804,  0.0809, -0.0028, -0.0668,  0.0301,\n",
      "         -0.0370,  0.0642,  0.0426, -0.0690,  0.0517, -0.0750,  0.0099, -0.0161,\n",
      "          0.0207, -0.0355, -0.0037,  0.1046, -0.0977,  0.0525, -0.0955,  0.0602,\n",
      "          0.0353, -0.0872, -0.0213, -0.0483,  0.0187,  0.0429, -0.0550, -0.0240,\n",
      "         -0.0398,  0.0297, -0.0864, -0.0200,  0.0996, -0.0294,  0.0456,  0.0795,\n",
      "          0.0766, -0.0413,  0.0143,  0.0872,  0.0407, -0.0344, -0.0892, -0.0982,\n",
      "          0.0423,  0.0428, -0.0244, -0.0307,  0.0376,  0.0824,  0.0577, -0.0819,\n",
      "         -0.0812,  0.1061, -0.0891, -0.0032],\n",
      "        [ 0.0891,  0.0380,  0.0288, -0.0939,  0.0628, -0.0113, -0.0824, -0.0302,\n",
      "          0.0257,  0.0029, -0.0528,  0.0632,  0.0806,  0.0237,  0.0142,  0.1014,\n",
      "          0.0590, -0.0135, -0.0824, -0.0249, -0.0497,  0.0711, -0.0818,  0.0006,\n",
      "         -0.0758,  0.0822, -0.0261,  0.0569,  0.0806,  0.0795,  0.0650,  0.0331,\n",
      "          0.0887,  0.0787, -0.0838,  0.0160,  0.0983,  0.0128,  0.0128,  0.1028,\n",
      "          0.0321, -0.0978,  0.0312,  0.0174,  0.0242,  0.0694, -0.0456,  0.0427,\n",
      "         -0.0325, -0.0638, -0.0315,  0.0590, -0.0014,  0.0529, -0.0247,  0.0809,\n",
      "         -0.0391,  0.0281, -0.0585, -0.0178, -0.0856,  0.0380, -0.0553,  0.0251,\n",
      "         -0.0046,  0.0508,  0.0529,  0.0998, -0.0325, -0.0073, -0.0549,  0.0893,\n",
      "          0.0216,  0.0462,  0.1043,  0.0795, -0.0486, -0.0408,  0.0872,  0.1079,\n",
      "          0.0485,  0.1040, -0.0116, -0.0940]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0948,  0.0424,  0.0744, -0.0224, -0.0348, -0.0767, -0.0399, -0.0581,\n",
      "         0.0977,  0.1080], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try a random 32x32 input.\n",
    "Note: expected input size of this net (LeNet) is 32x32. To use this net on\n",
    "MNIST dataset, please resize the images from the dataset to 32x32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.3163, -2.0846,  0.1915,  ...,  0.8722,  1.2185, -0.5782],\n",
      "          [ 1.9874, -1.5939, -0.1438,  ..., -0.0492, -0.0532,  0.1879],\n",
      "          [ 0.6473,  1.2057, -0.5424,  ...,  0.2893, -1.0658, -0.9620],\n",
      "          ...,\n",
      "          [-1.9396,  0.0948,  0.3026,  ..., -1.2592,  0.4310, -0.3891],\n",
      "          [ 2.4961, -0.3515, -0.9477,  ..., -1.0689, -0.0764, -0.1305],\n",
      "          [ 1.0799,  0.2992,  1.0441,  ...,  1.6731,  1.9855, -0.8755]]]])\n",
      "tensor([[[[0.2039, 0.5168, 1.0957,  ..., 1.2081, 1.0467, 1.1356],\n",
      "          [0.4856, 0.9123, 0.4845,  ..., 1.5188, 0.2627, 0.0606],\n",
      "          [0.4277, 0.0147, 0.8012,  ..., 0.9009, 0.4400, 0.8268],\n",
      "          ...,\n",
      "          [0.6578, 0.6148, 0.6923,  ..., 0.6460, 1.0683, 0.0098],\n",
      "          [1.3545, 1.1577, 0.0000,  ..., 0.4076, 0.0601, 0.8060],\n",
      "          [1.7720, 0.0000, 0.6242,  ..., 0.3297, 0.9644, 0.2648]],\n",
      "\n",
      "         [[0.5429, 0.7647, 0.6270,  ..., 0.0000, 0.5830, 0.4878],\n",
      "          [0.4415, 0.8091, 0.6923,  ..., 0.9195, 0.6805, 0.9074],\n",
      "          [1.4172, 1.1807, 0.6947,  ..., 0.8260, 0.1157, 0.0000],\n",
      "          ...,\n",
      "          [1.1116, 1.0319, 0.8697,  ..., 0.5179, 0.0000, 0.3336],\n",
      "          [1.0215, 0.4049, 0.0000,  ..., 0.0392, 0.0872, 1.0381],\n",
      "          [0.7387, 0.0000, 0.4041,  ..., 0.0000, 0.4759, 1.0756]],\n",
      "\n",
      "         [[0.6746, 0.0415, 0.7961,  ..., 0.0038, 0.7103, 0.5999],\n",
      "          [0.1889, 0.6965, 0.1800,  ..., 0.6693, 0.3850, 0.3520],\n",
      "          [0.3511, 0.4166, 0.5771,  ..., 0.6077, 0.7354, 0.2951],\n",
      "          ...,\n",
      "          [0.8048, 0.1641, 0.4744,  ..., 0.6886, 0.0682, 0.2200],\n",
      "          [0.7286, 0.8487, 0.0354,  ..., 0.4626, 0.0506, 0.4711],\n",
      "          [1.0729, 0.0000, 0.0888,  ..., 0.0000, 0.2758, 0.3630]],\n",
      "\n",
      "         [[0.0000, 0.8303, 0.7807,  ..., 0.5700, 0.7027, 0.2587],\n",
      "          [1.4731, 0.4608, 0.3460,  ..., 0.8982, 0.7044, 0.7137],\n",
      "          [0.5136, 0.8765, 0.5414,  ..., 1.1332, 0.4839, 1.1922],\n",
      "          ...,\n",
      "          [0.8661, 0.3862, 1.0392,  ..., 0.2826, 0.7530, 0.4733],\n",
      "          [0.9468, 0.5401, 0.4463,  ..., 0.6470, 0.8411, 0.9766],\n",
      "          [0.9777, 0.4468, 1.0894,  ..., 0.7268, 1.6590, 0.4914]],\n",
      "\n",
      "         [[1.6493, 0.3604, 0.6613,  ..., 0.1555, 0.3914, 0.2393],\n",
      "          [0.7462, 0.4434, 0.8521,  ..., 0.6878, 0.4423, 0.3996],\n",
      "          [0.2697, 0.3835, 0.6524,  ..., 1.2100, 0.4351, 0.7426],\n",
      "          ...,\n",
      "          [0.1025, 0.2456, 0.8592,  ..., 0.5972, 0.5068, 0.6166],\n",
      "          [0.1636, 0.7092, 0.8395,  ..., 0.7959, 0.5045, 0.0000],\n",
      "          [0.7459, 0.3046, 0.0244,  ..., 0.5208, 0.3205, 0.9203]],\n",
      "\n",
      "         [[1.0060, 1.0322, 0.4256,  ..., 1.1873, 0.3580, 0.5455],\n",
      "          [0.7260, 0.7901, 0.0284,  ..., 0.6398, 0.3519, 1.2419],\n",
      "          [0.9600, 0.0000, 0.2557,  ..., 1.0941, 2.4220, 0.8137],\n",
      "          ...,\n",
      "          [0.7534, 0.1476, 0.1526,  ..., 0.6435, 0.8585, 0.2599],\n",
      "          [2.2716, 0.1570, 1.1630,  ..., 0.3958, 0.8803, 0.9279],\n",
      "          [1.8470, 1.2998, 1.6748,  ..., 1.0948, 2.0883, 0.4158]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "tensor([[[[2.2431e-02, 1.8263e-01, 2.2717e-01, 1.1067e-03, 6.2583e-02,\n",
      "           1.0427e-01],\n",
      "          [2.8041e-01, 0.0000e+00, 1.4311e-01, 2.7645e-01, 0.0000e+00,\n",
      "           5.5733e-02],\n",
      "          [2.0779e-01, 2.2386e-01, 0.0000e+00, 2.7135e-01, 1.1982e-01,\n",
      "           1.9684e-01],\n",
      "          [2.3863e-01, 1.4149e-01, 3.6523e-01, 1.0799e-01, 1.3493e-01,\n",
      "           2.4235e-02],\n",
      "          [2.0491e-01, 1.2128e-02, 8.7840e-02, 2.2476e-01, 3.0923e-01,\n",
      "           1.1985e-01],\n",
      "          [2.5436e-01, 5.4967e-02, 1.2024e-01, 5.3444e-02, 2.3926e-02,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[3.4203e-01, 2.7280e-01, 2.9868e-01, 5.9783e-01, 2.0754e-01,\n",
      "           2.0403e-01],\n",
      "          [4.7247e-01, 6.7008e-01, 6.7208e-01, 4.3981e-01, 4.7156e-01,\n",
      "           7.3248e-01],\n",
      "          [4.3282e-01, 5.3126e-01, 4.2621e-01, 2.7862e-01, 2.6821e-01,\n",
      "           5.8059e-01],\n",
      "          [5.7757e-01, 6.5661e-01, 3.5436e-01, 4.6147e-01, 2.2702e-01,\n",
      "           3.4617e-01],\n",
      "          [3.7396e-01, 4.0764e-01, 1.6874e-01, 4.0649e-01, 5.1227e-01,\n",
      "           4.5973e-01],\n",
      "          [1.3497e-01, 3.3361e-01, 5.3239e-01, 7.6190e-01, 6.1900e-01,\n",
      "           1.1147e-01]],\n",
      "\n",
      "         [[3.4910e-01, 5.1350e-01, 3.0708e-01, 1.1552e-01, 6.4440e-01,\n",
      "           1.5267e-01],\n",
      "          [3.1652e-01, 3.9794e-01, 1.4006e-01, 7.5042e-02, 1.7665e-01,\n",
      "           0.0000e+00],\n",
      "          [4.5599e-01, 1.6290e-01, 3.3269e-01, 5.1952e-01, 6.6258e-01,\n",
      "           4.6159e-01],\n",
      "          [5.7096e-01, 8.2838e-02, 2.0810e-01, 2.4027e-01, 2.1259e-01,\n",
      "           3.1710e-01],\n",
      "          [3.2400e-01, 4.0107e-01, 6.2983e-02, 2.6924e-01, 0.0000e+00,\n",
      "           5.0324e-01],\n",
      "          [4.7963e-01, 5.3756e-01, 0.0000e+00, 7.4166e-01, 3.0608e-01,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[4.1825e-01, 5.6165e-01, 4.3993e-01, 5.0297e-01, 3.2644e-01,\n",
      "           5.8387e-01],\n",
      "          [8.0415e-01, 7.7226e-01, 7.3780e-01, 5.4989e-01, 5.0839e-01,\n",
      "           8.5003e-01],\n",
      "          [5.4708e-01, 5.0280e-01, 4.2808e-01, 4.9019e-01, 6.1917e-01,\n",
      "           3.7475e-01],\n",
      "          [5.2358e-01, 6.3075e-01, 7.0456e-01, 9.2518e-01, 7.6372e-01,\n",
      "           3.6348e-01],\n",
      "          [5.6823e-01, 4.1385e-01, 3.6813e-01, 3.9498e-01, 7.7788e-01,\n",
      "           5.4460e-01],\n",
      "          [5.4355e-01, 5.1788e-01, 8.8930e-01, 6.0573e-01, 5.2831e-01,\n",
      "           6.8549e-01]],\n",
      "\n",
      "         [[2.6209e-01, 6.2954e-02, 3.3718e-01, 1.2120e-01, 0.0000e+00,\n",
      "           3.6491e-01],\n",
      "          [4.6828e-01, 9.8068e-02, 4.0807e-01, 1.6187e-01, 2.6272e-01,\n",
      "           3.1797e-01],\n",
      "          [2.7475e-01, 1.7436e-01, 3.9416e-01, 4.5881e-01, 3.6571e-01,\n",
      "           1.4650e-01],\n",
      "          [3.4455e-01, 5.1197e-02, 1.4429e-01, 1.8954e-02, 3.8977e-01,\n",
      "           5.9476e-02],\n",
      "          [1.6459e-01, 1.7536e-01, 1.2275e-01, 2.1331e-01, 3.7473e-01,\n",
      "           3.3668e-01],\n",
      "          [4.2310e-01, 7.6310e-02, 2.0936e-01, 1.3069e-01, 1.9347e-01,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[8.4922e-01, 7.1956e-01, 4.6781e-01, 3.3941e-01, 6.4073e-01,\n",
      "           4.9770e-01],\n",
      "          [6.9265e-01, 7.3951e-01, 4.9381e-01, 5.8636e-01, 5.8649e-01,\n",
      "           5.7979e-01],\n",
      "          [8.5910e-01, 8.4862e-01, 6.8296e-01, 7.0483e-01, 4.8131e-01,\n",
      "           7.9414e-01],\n",
      "          [7.2353e-01, 5.2480e-01, 4.0981e-01, 8.0571e-01, 9.1652e-01,\n",
      "           7.9957e-01],\n",
      "          [1.0586e+00, 6.7007e-01, 3.9006e-01, 6.3766e-01, 1.0929e+00,\n",
      "           5.5294e-01],\n",
      "          [1.0125e+00, 3.1020e-01, 4.2400e-01, 4.6195e-01, 7.6311e-01,\n",
      "           5.7310e-01]],\n",
      "\n",
      "         [[1.9790e-01, 3.7123e-01, 2.2196e-01, 7.7102e-02, 3.3145e-02,\n",
      "           3.7603e-01],\n",
      "          [1.7677e-01, 2.2395e-01, 2.2730e-01, 1.0618e-01, 1.1451e-01,\n",
      "           2.5568e-01],\n",
      "          [3.1538e-01, 1.6992e-01, 2.3194e-01, 2.9688e-01, 2.7134e-01,\n",
      "           0.0000e+00],\n",
      "          [2.9511e-01, 2.4911e-01, 2.2487e-01, 1.7093e-01, 2.9195e-01,\n",
      "           2.2736e-01],\n",
      "          [4.6164e-01, 1.0193e-01, 4.3262e-01, 2.6815e-01, 0.0000e+00,\n",
      "           5.1158e-01],\n",
      "          [9.2746e-02, 2.8707e-01, 2.6746e-02, 3.4778e-01, 6.4514e-02,\n",
      "           1.1858e-01]],\n",
      "\n",
      "         [[4.0767e-01, 5.3850e-01, 1.4054e-01, 3.6052e-01, 5.2309e-01,\n",
      "           2.4392e-01],\n",
      "          [4.0414e-01, 5.0465e-01, 3.6018e-01, 3.6432e-01, 6.3283e-01,\n",
      "           5.8443e-01],\n",
      "          [7.1943e-01, 1.6408e-01, 4.5074e-01, 3.4556e-01, 2.3763e-01,\n",
      "           3.0461e-01],\n",
      "          [5.3804e-01, 3.8443e-01, 3.9254e-01, 5.9110e-01, 6.9850e-01,\n",
      "           8.5450e-01],\n",
      "          [3.1201e-01, 3.3433e-01, 1.4888e-01, 3.9719e-01, 1.7915e-01,\n",
      "           3.7470e-01],\n",
      "          [4.1965e-01, 6.7766e-01, 2.8383e-01, 8.5562e-01, 5.6994e-01,\n",
      "           5.9001e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8291e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.4413e-01, 0.0000e+00, 1.1691e-01,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 1.5435e-01, 0.0000e+00, 0.0000e+00, 5.7543e-02,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9497e-01, 0.0000e+00,\n",
      "           2.1798e-01],\n",
      "          [2.9454e-02, 0.0000e+00, 0.0000e+00, 1.0512e-01, 0.0000e+00,\n",
      "           5.6331e-02]],\n",
      "\n",
      "         [[0.0000e+00, 4.3449e-02, 6.9599e-02, 0.0000e+00, 0.0000e+00,\n",
      "           8.4061e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5523e-02,\n",
      "           0.0000e+00],\n",
      "          [6.1853e-02, 1.8371e-01, 2.6039e-02, 0.0000e+00, 1.2481e-01,\n",
      "           1.4183e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2404e-01,\n",
      "           1.4082e-01],\n",
      "          [2.6700e-01, 3.0325e-01, 9.5510e-02, 3.1832e-01, 4.6344e-02,\n",
      "           5.8241e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.2767e-02, 1.0931e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 1.5334e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.1521e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2531e-02,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9690e-02, 0.0000e+00,\n",
      "           1.6134e-02],\n",
      "          [0.0000e+00, 8.4783e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [7.2035e-02, 1.4788e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[3.0714e-01, 3.8375e-01, 6.5336e-02, 3.4296e-02, 2.2539e-01,\n",
      "           1.3709e-01],\n",
      "          [1.9984e-01, 2.4594e-01, 0.0000e+00, 2.1886e-01, 1.8750e-01,\n",
      "           4.2717e-02],\n",
      "          [4.2409e-01, 2.2882e-01, 3.9115e-01, 3.7827e-01, 3.2110e-01,\n",
      "           2.6083e-01],\n",
      "          [2.2551e-01, 2.1237e-01, 0.0000e+00, 4.6250e-01, 1.4394e-01,\n",
      "           3.6497e-01],\n",
      "          [2.5186e-01, 4.7448e-01, 2.3583e-01, 3.4040e-01, 3.7932e-01,\n",
      "           4.8088e-01],\n",
      "          [1.5543e-01, 1.5094e-02, 0.0000e+00, 4.9208e-01, 2.1891e-01,\n",
      "           1.9763e-01]],\n",
      "\n",
      "         [[2.6615e-01, 1.6512e-01, 2.0971e-02, 5.1734e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [7.9137e-03, 1.3936e-01, 1.3511e-01, 6.9012e-02, 8.7639e-02,\n",
      "           4.7343e-02],\n",
      "          [4.4756e-02, 0.0000e+00, 1.1624e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7355e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.7243e-01, 0.0000e+00, 0.0000e+00, 9.0331e-02, 0.0000e+00,\n",
      "           5.4154e-01],\n",
      "          [0.0000e+00, 4.7501e-03, 3.2638e-02, 8.3381e-02, 2.2575e-02,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 7.5799e-03, 0.0000e+00, 0.0000e+00,\n",
      "           5.1295e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6632e-05, 1.0340e-01,\n",
      "           1.9864e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 1.7714e-01, 2.6987e-02, 1.9428e-01,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           2.5860e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 7.7570e-02, 3.7603e-01, 0.0000e+00,\n",
      "           3.6075e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5060e-01, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[6.3445e-01, 4.3246e-01, 5.5171e-01, 6.3783e-01, 5.8366e-01,\n",
      "           4.8182e-01],\n",
      "          [4.9238e-01, 3.4355e-01, 2.3139e-01, 2.5288e-01, 6.3281e-01,\n",
      "           4.8251e-01],\n",
      "          [8.1893e-01, 5.5607e-01, 5.0228e-01, 6.5138e-01, 1.7716e-01,\n",
      "           8.3466e-01],\n",
      "          [5.2768e-01, 1.9281e-01, 6.9664e-01, 7.1235e-01, 2.6122e-01,\n",
      "           8.8625e-01],\n",
      "          [6.8295e-01, 7.9936e-01, 4.0783e-01, 5.1300e-01, 1.5118e-01,\n",
      "           6.2239e-01],\n",
      "          [4.8816e-01, 2.6373e-01, 0.0000e+00, 3.4906e-01, 9.0237e-01,\n",
      "           3.9350e-01]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "tensor([[ 0.0265,  0.0455,  0.0418,  0.0187, -0.0074, -0.1501,  0.0255, -0.0673,\n",
      "          0.0775,  0.2366]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random\n",
    "gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n",
    "    package only supports inputs that are a mini-batch of samples, and not\n",
    "    a single sample.\n",
    "\n",
    "    For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
    "    ``nSamples x nChannels x Height x Width``.\n",
    "\n",
    "    If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
    "    a fake batch dimension.</p></div>\n",
    "\n",
    "Before proceeding further, let's recap all the classes you’ve seen so far.\n",
    "\n",
    "**Recap:**\n",
    "  -  ``torch.Tensor`` - A *multi-dimensional array* with support for autograd\n",
    "     operations like ``backward()``. Also *holds the gradient* w.r.t. the\n",
    "     tensor.\n",
    "  -  ``nn.Module`` - Neural network module. *Convenient way of\n",
    "     encapsulating parameters*, with helpers for moving them to GPU,\n",
    "     exporting, loading, etc.\n",
    "  -  ``nn.Parameter`` - A kind of Tensor, that is *automatically\n",
    "     registered as a parameter when assigned as an attribute to a*\n",
    "     ``Module``.\n",
    "  -  ``autograd.Function`` - Implements *forward and backward definitions\n",
    "     of an autograd operation*. Every ``Tensor`` operation creates at\n",
    "     least a single ``Function`` node that connects to functions that\n",
    "     created a ``Tensor`` and *encodes its history*.\n",
    "\n",
    "**At this point, we covered:**\n",
    "  -  Defining a neural network\n",
    "  -  Processing inputs and calling backward\n",
    "\n",
    "**Still Left:**\n",
    "  -  Computing the loss\n",
    "  -  Updating the weights of the network\n",
    "\n",
    "Loss Function\n",
    "-------------\n",
    "A loss function takes the (output, target) pair of inputs, and computes a\n",
    "value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different\n",
    "`loss functions <https://pytorch.org/docs/nn.html#loss-functions>`_ under the\n",
    "nn package .\n",
    "A simple loss is: ``nn.MSELoss`` which computes the mean-squared error\n",
    "between the input and the target.\n",
    "\n",
    "For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5253, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow ``loss`` in the backward direction, using its\n",
    "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
    "like this:\n",
    "\n",
    "::\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
    "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
    "will have their ``.grad`` Tensor accumulated with the gradient.\n",
    "\n",
    "For illustration, let us follow a few steps backward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7fbf360c3208>\n",
      "<AddmmBackward object at 0x7fbf360c3160>\n",
      "<AccumulateGrad object at 0x7fbf360c3208>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backprop\n",
    "--------\n",
    "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
    "You need to clear the existing gradients though, else gradients will be\n",
    "accumulated to existing gradients.\n",
    "\n",
    "\n",
    "Now we shall call ``loss.backward()``, and have a look at conv1's bias\n",
    "gradients before and after the backward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0059, -0.0044,  0.0028, -0.0006, -0.0027, -0.0043])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have seen how to use loss functions.\n",
    "\n",
    "**Read Later:**\n",
    "\n",
    "  The neural network package contains various modules and loss functions\n",
    "  that form the building blocks of deep neural networks. A full list with\n",
    "  documentation is `here <https://pytorch.org/docs/nn>`_.\n",
    "\n",
    "**The only thing left to learn is:**\n",
    "\n",
    "  - Updating the weights of the network\n",
    "\n",
    "Update the weights\n",
    "------------------\n",
    "The simplest update rule used in practice is the Stochastic Gradient\n",
    "Descent (SGD):\n",
    "\n",
    "     ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "We can implement this using simple python code:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    for f in net.parameters():\n",
    "        f.data.sub_(f.grad.data * learning_rate)\n",
    "\n",
    "However, as you use neural networks, you want to use various different\n",
    "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
    "To enable this, we built a small package: ``torch.optim`` that\n",
    "implements all these methods. Using it is very simple:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Note::\n",
    "\n",
    "      Observe how gradient buffers had to be manually set to zero using\n",
    "      ``optimizer.zero_grad()``. This is because gradients are accumulated\n",
    "      as explained in `Backprop`_ section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
